{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries and Set Up Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/beau/anaconda3/envs/dev/lib/python3.10/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables from the .env in the local environment\n",
    "load_dotenv()\n",
    "\n",
    "nyt_api_key = os.getenv(\"NYT_API_KEY\")\n",
    "tmdb_api_key = os.getenv(\"TMDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1b5zds6gWGokXaLgBHuj9hd6jSCI66lE\n",
      "fde780b993cb280d3ebc6b7301d20281\n"
     ]
    }
   ],
   "source": [
    "print(nyt_api_key)\n",
    "print(tmdb_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the New York Times API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=1b5zds6gWGokXaLgBHuj9hd6jSCI66lE&begin_date=20130101&end_date=20230531&fq=section_name:\"Movies\" AND type_of_material:\"Review\" AND headline:\"love\"&sort=newest&fl=headline,web_url,snippet,source,keywords,pub_date,byline,word_count\n"
     ]
    }
   ],
   "source": [
    "# Set the base URL\n",
    "url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?\"\n",
    "\n",
    "# Filter for movie reviews with \"love\" in the headline\n",
    "# section_name should be \"Movies\"\n",
    "# type_of_material should be \"Review\"\n",
    "filter_query = 'section_name:\"Movies\" AND type_of_material:\"Review\" AND headline:\"love\"'\n",
    "\n",
    "# Use a sort filter, sort by newest\n",
    "sort = \"newest\"\n",
    "\n",
    "# Select the following fields to return:\n",
    "# headline, web_url, snippet, source, keywords, pub_date, byline, word_count\n",
    "field_list = \"headline,web_url,snippet,source,keywords,pub_date,byline,word_count\"\n",
    "\n",
    "# Search for reviews published between a begin and end date\n",
    "begin_date = \"20130101\"\n",
    "end_date = \"20230531\"\n",
    "\n",
    "# Build URL\n",
    "#api_key = \"1b5zds6gWGokXaLgBHuj9hd6jSCI66lE\" \n",
    "api_key = tmdb_api_key\n",
    "\n",
    "query_url = (f\"{url}api-key={nyt_api_key}&begin_date={begin_date}&end_date={end_date}&fq={filter_query}&sort={sort}&fl={field_list}\")\n",
    "\n",
    "print(query_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving page 0 of reviews...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0 retrieved\n",
      "Retrieving page 1 of reviews...\n",
      "Page 1 retrieved\n",
      "Retrieving page 2 of reviews...\n",
      "Page 2 retrieved\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the reviews\n",
    "reviews_list = []\n",
    "\n",
    "# loop through pages 0-19\n",
    "for page in range(3):\n",
    "    # create query with a page number\n",
    "    page_url = f\"{query_url}&page={page}\"\n",
    "    # API results show 10 articles at a time\n",
    "    print(f\"Retrieving page {page} of reviews...\")\n",
    "    \n",
    "    # Make a \"GET\" request and retrieve the JSON\n",
    "    response = requests.get(page_url)\n",
    "    reviews = response.json()\n",
    "    \n",
    "    # Add a twelve second interval between queries to stay within API query limits\n",
    "    time.sleep(12)\n",
    "    \n",
    "    # Try and save the reviews to the reviews_list\n",
    "    try:\n",
    "        # loop through the reviews[\"response\"][\"docs\"] and append each review to the list\n",
    "        for review in reviews[\"response\"][\"docs\"]:\n",
    "            reviews_list.append(review)\n",
    "\n",
    "        # Print the page that was just retrieved\n",
    "        print(f\"Page {page} retrieved\") \n",
    "\n",
    "    except KeyError:\n",
    "        # Print the page number that had no results then break from the loop\n",
    "        print(f\"No results on page {page}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"web_url\": \"https://www.nytimes.com/2023/05/25/movies/the-attachment-diaries-review.html\",\n",
      "        \"snippet\": \"A gynecologist and her patient form a horrifyingly twisted connection in this batty, bloody Argentine melodrama.\",\n",
      "        \"source\": \"The New York Times\",\n",
      "        \"headline\": {\n",
      "            \"main\": \"\\u2018The Attachment Diaries\\u2019 Review: Love, Sick\",\n",
      "            \"kicker\": null,\n",
      "            \"content_kicker\": null,\n",
      "            \"print_headline\": \"The Attachment Diaries\",\n",
      "            \"name\": null,\n",
      "            \"seo\": null,\n",
      "            \"sub\": null\n",
      "        },\n",
      "        \"keywords\": [\n",
      "            {\n",
      "                \"name\": \"subject\",\n",
      "                \"value\": \"Movies\",\n",
      "                \"rank\": 1,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"creative_works\",\n",
      "                \"value\": \"The Attachment Diaries (Movie)\",\n",
      "                \"rank\": 2,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"Diment, Valentin Javier\",\n",
      "                \"rank\": 3,\n",
      "                \"major\": \"N\"\n",
      "            }\n",
      "        ],\n",
      "        \"pub_date\": \"2023-05-25T11:00:03+0000\",\n",
      "        \"byline\": {\n",
      "            \"original\": \"By Jeannette Catsoulis\",\n",
      "            \"person\": [\n",
      "                {\n",
      "                    \"firstname\": \"Jeannette\",\n",
      "                    \"middlename\": null,\n",
      "                    \"lastname\": \"Catsoulis\",\n",
      "                    \"qualifier\": null,\n",
      "                    \"title\": null,\n",
      "                    \"role\": \"reported\",\n",
      "                    \"organization\": \"\",\n",
      "                    \"rank\": 1\n",
      "                }\n",
      "            ],\n",
      "            \"organization\": null\n",
      "        },\n",
      "        \"word_count\": 295\n",
      "    },\n",
      "    {\n",
      "        \"web_url\": \"https://www.nytimes.com/2023/05/04/movies/whats-love-got-to-do-with-it-review.html\",\n",
      "        \"snippet\": \"Two childhood friends navigate cultural differences in this pleasantly uncontentious romantic comedy.\",\n",
      "        \"source\": \"The New York Times\",\n",
      "        \"headline\": {\n",
      "            \"main\": \"Review: \\u2018What\\u2019s Love Got to Do With It?\\u2019 Probably a Lot\",\n",
      "            \"kicker\": null,\n",
      "            \"content_kicker\": null,\n",
      "            \"print_headline\": \"What\\u2019s Love Got to Do With It?\",\n",
      "            \"name\": null,\n",
      "            \"seo\": null,\n",
      "            \"sub\": null\n",
      "        },\n",
      "        \"keywords\": [\n",
      "            {\n",
      "                \"name\": \"subject\",\n",
      "                \"value\": \"Movies\",\n",
      "                \"rank\": 1,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"Kapur, Shekhar\",\n",
      "                \"rank\": 2,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"James, Lily\",\n",
      "                \"rank\": 3,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"Azmi, Shabana\",\n",
      "                \"rank\": 4,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"Thompson, Emma\",\n",
      "                \"rank\": 5,\n",
      "                \"major\": \"N\"\n",
      "            }\n",
      "        ],\n",
      "        \"pub_date\": \"2023-05-04T17:16:45+0000\",\n",
      "        \"byline\": {\n",
      "            \"original\": \"By Jeannette Catsoulis\",\n",
      "            \"person\": [\n",
      "                {\n",
      "                    \"firstname\": \"Jeannette\",\n",
      "                    \"middlename\": null,\n",
      "                    \"lastname\": \"Catsoulis\",\n",
      "                    \"qualifier\": null,\n",
      "                    \"title\": null,\n",
      "                    \"role\": \"reported\",\n",
      "                    \"organization\": \"\",\n",
      "                    \"rank\": 1\n",
      "                }\n",
      "            ],\n",
      "            \"organization\": null\n",
      "        },\n",
      "        \"word_count\": 287\n",
      "    },\n",
      "    {\n",
      "        \"web_url\": \"https://www.nytimes.com/2023/05/04/movies/you-can-live-forever-review.html\",\n",
      "        \"snippet\": \"Religion comes between two girls falling in love in the 1990s in this sweet coming-of-age film bathed in grunge hues.\",\n",
      "        \"source\": \"The New York Times\",\n",
      "        \"headline\": {\n",
      "            \"main\": \"\\u2018You Can Live Forever\\u2019 Review: Do You Love Me Now?\",\n",
      "            \"kicker\": null,\n",
      "            \"content_kicker\": null,\n",
      "            \"print_headline\": \"You Can Live Forever\",\n",
      "            \"name\": null,\n",
      "            \"seo\": null,\n",
      "            \"sub\": null\n",
      "        },\n",
      "        \"keywords\": [\n",
      "            {\n",
      "                \"name\": \"subject\",\n",
      "                \"value\": \"Movies\",\n",
      "                \"rank\": 1,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"creative_works\",\n",
      "                \"value\": \"You Can Live Forever (Movie)\",\n",
      "                \"rank\": 2,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"Slutsky, Mark\",\n",
      "                \"rank\": 3,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"Watts, Sarah (Film Director)\",\n",
      "                \"rank\": 4,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"O'Driscoll, Anwen\",\n",
      "                \"rank\": 5,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"Laporte, June (Actor)\",\n",
      "                \"rank\": 6,\n",
      "                \"major\": \"N\"\n",
      "            }\n",
      "        ],\n",
      "        \"pub_date\": \"2023-05-04T11:00:08+0000\",\n",
      "        \"byline\": {\n",
      "            \"original\": \"By Elisabeth Vincentelli\",\n",
      "            \"person\": [\n",
      "                {\n",
      "                    \"firstname\": \"Elisabeth\",\n",
      "                    \"middlename\": null,\n",
      "                    \"lastname\": \"Vincentelli\",\n",
      "                    \"qualifier\": null,\n",
      "                    \"title\": null,\n",
      "                    \"role\": \"reported\",\n",
      "                    \"organization\": \"\",\n",
      "                    \"rank\": 1\n",
      "                }\n",
      "            ],\n",
      "            \"organization\": null\n",
      "        },\n",
      "        \"word_count\": 294\n",
      "    },\n",
      "    {\n",
      "        \"web_url\": \"https://www.nytimes.com/2023/04/21/movies/a-tourists-guide-to-love-review.html\",\n",
      "        \"snippet\": \"Rachael Leigh Cook stars in this bland rom-com as a travel executive exploring Vietnam and getting over a breakup.\",\n",
      "        \"source\": \"The New York Times\",\n",
      "        \"headline\": {\n",
      "            \"main\": \"\\u2018A Tourist\\u2019s Guide to Love\\u2019 Review: A Wearyingly Familiar Trip\",\n",
      "            \"kicker\": null,\n",
      "            \"content_kicker\": null,\n",
      "            \"print_headline\": \"A Tourist\\u2019s  Guide to Love\",\n",
      "            \"name\": null,\n",
      "            \"seo\": null,\n",
      "            \"sub\": null\n",
      "        },\n",
      "        \"keywords\": [\n",
      "            {\n",
      "                \"name\": \"subject\",\n",
      "                \"value\": \"Movies\",\n",
      "                \"rank\": 1,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"creative_works\",\n",
      "                \"value\": \"A Tourist's Guide to Love (Movie)\",\n",
      "                \"rank\": 2,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"Tsuchida, Steven\",\n",
      "                \"rank\": 3,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"Cook, Rachael Leigh\",\n",
      "                \"rank\": 4,\n",
      "                \"major\": \"N\"\n",
      "            }\n",
      "        ],\n",
      "        \"pub_date\": \"2023-04-21T07:03:25+0000\",\n",
      "        \"byline\": {\n",
      "            \"original\": \"By Elisabeth Vincentelli\",\n",
      "            \"person\": [\n",
      "                {\n",
      "                    \"firstname\": \"Elisabeth\",\n",
      "                    \"middlename\": null,\n",
      "                    \"lastname\": \"Vincentelli\",\n",
      "                    \"qualifier\": null,\n",
      "                    \"title\": null,\n",
      "                    \"role\": \"reported\",\n",
      "                    \"organization\": \"\",\n",
      "                    \"rank\": 1\n",
      "                }\n",
      "            ],\n",
      "            \"organization\": null\n",
      "        },\n",
      "        \"word_count\": 276\n",
      "    },\n",
      "    {\n",
      "        \"web_url\": \"https://www.nytimes.com/2023/04/20/movies/other-peoples-children-review.html\",\n",
      "        \"snippet\": \"A radiant Virginie Efira stars as a Parisian teacher who blissfully falls for a man and his 4-year-old daughter, complicating everyone\\u2019s lives.\",\n",
      "        \"source\": \"The New York Times\",\n",
      "        \"headline\": {\n",
      "            \"main\": \"\\u2018Other People\\u2019s Children\\u2019 Review: True Romance\",\n",
      "            \"kicker\": \"Critic\\u2019s pick\",\n",
      "            \"content_kicker\": null,\n",
      "            \"print_headline\": \"Intoxicating Love With a Sobering Turn\",\n",
      "            \"name\": null,\n",
      "            \"seo\": null,\n",
      "            \"sub\": null\n",
      "        },\n",
      "        \"keywords\": [\n",
      "            {\n",
      "                \"name\": \"subject\",\n",
      "                \"value\": \"Movies\",\n",
      "                \"rank\": 1,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"persons\",\n",
      "                \"value\": \"Zlotowski, Rebecca\",\n",
      "                \"rank\": 2,\n",
      "                \"major\": \"N\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"creative_works\",\n",
      "                \"value\": \"Other People's Children (Movie)\",\n",
      "                \"rank\": 3,\n",
      "                \"major\": \"N\"\n",
      "            }\n",
      "        ],\n",
      "        \"pub_date\": \"2023-04-20T15:35:13+0000\",\n",
      "        \"byline\": {\n",
      "            \"original\": \"By Manohla Dargis\",\n",
      "            \"person\": [\n",
      "                {\n",
      "                    \"firstname\": \"Manohla\",\n",
      "                    \"middlename\": null,\n",
      "                    \"lastname\": \"Dargis\",\n",
      "                    \"qualifier\": null,\n",
      "                    \"title\": null,\n",
      "                    \"role\": \"reported\",\n",
      "                    \"organization\": \"\",\n",
      "                    \"rank\": 1\n",
      "                }\n",
      "            ],\n",
      "            \"organization\": null\n",
      "        },\n",
      "        \"word_count\": 801\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Preview the first 5 results in JSON format\n",
    "# Use json.dumps with argument indent=4 to format data\n",
    "print(json.dumps(reviews_list[:5], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reviews_list to a Pandas DataFrame using json_normalize()\n",
    "df = pd.json_normalize(reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the title from the \"headline.main\" column and\n",
    "# save it to a new column \"title\"\n",
    "# Title is between unicode characters \\u2018 and \\u2019. \n",
    "# End string should include \" Review\" to avoid cutting title early\n",
    "df['title'] = df['headline.main'].str.extract(\"\\u2018(.+?)\\u2019 Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'name' and 'value' from items in \"keywords\" column\n",
    "def extract_keywords(keyword_list):\n",
    "    extracted_keywords = \"\"\n",
    "    for item in keyword_list:\n",
    "        # Extract 'name' and 'value'\n",
    "        keyword = f\"{item['name']}: {item['value']};\" \n",
    "        # Append the keyword item to the extracted_keywords list\n",
    "        extracted_keywords += keyword\n",
    "    return extracted_keywords\n",
    "\n",
    "# Fix the \"keywords\" column by converting cells from a list to a string\n",
    "df['keywords'] = df['keywords'].apply(extract_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list from the \"title\" column using to_list()\n",
    "# These titles will be used in the query for The Movie Database\n",
    "titles = df['title'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access The Movie Database API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare The Movie Database query\n",
    "url = \"https://api.themoviedb.org/3/search/movie?query=\"\n",
    "tmdb_key_string = \"&api_key=\" + tmdb_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&api_key=fde780b993cb280d3ebc6b7301d20281'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb_key_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fde780b993cb280d3ebc6b7301d20281\n"
     ]
    }
   ],
   "source": [
    "print(tmdb_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie found: The Attachment Diaries\n",
      "Movie found: nan\n",
      "Movie found: You Can Live Forever\n",
      "Movie found: A Tourist’s Guide to Love\n",
      "Movie found: Other People’s Children\n",
      "Movie found: One True Loves\n",
      "Movie found: The Lost Weekend: A Love Story\n",
      "Movie found: A Thousand and One\n",
      "Movie found: Your Place or Mine\n",
      "Movie found: Love in the Time of Fentanyl\n",
      "Movie found: Pamela, a Love Story\n",
      "Movie found: In From the Side\n",
      "Movie found: After Love\n",
      "Movie found: Alcarràs\n",
      "Movie found: Nelly & Nadine\n",
      "Movie found: Lady Chatterley’s Lover\n",
      "Movie found: The Sound of Christmas\n",
      "Movie found: The Inspection\n",
      "Movie found: Bones and All\n",
      "Movie found: My Policeman\n",
      "Movie found: About Fate\n",
      "Movie found: Waiting for Bojangles\n",
      "Movie found: I Love My Dad\n",
      "Movie found: A Love Song\n",
      "Movie found: Alone Together\n",
      "Movie found: Art of Love\n",
      "Movie found: The Wheel\n",
      "Movie found: Thor: Love and Thunder\n",
      "Movie found: Both Sides of the Blade\n",
      "Movie found: Fire of Love\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the results\n",
    "tmdb_movies_list = []\n",
    "\n",
    "# Create a request counter to sleep the requests after a multiple\n",
    "# of 50 requests\n",
    "request_counter = 0\n",
    "# Loop through the titles\n",
    "for title in titles:\n",
    "    # Check if we need to sleep before making a request\n",
    "    if request_counter > 0 and request_counter % 50 == 0:\n",
    "        print(\"Sleeping for 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "    # Add 1 to the request counter\n",
    "    request_counter += 1\n",
    "    # Perform a \"GET\" request for The Movie Database\n",
    "    response = requests.get(f\"https://api.themoviedb.org/3/search/movie?query={title}&api_key={tmdb_api_key}\")\n",
    "\n",
    "    # Include a try clause to search for the full movie details.\n",
    "    # Use the except clause to print out a statement if a movie\n",
    "    # is not found.\n",
    "    try:\n",
    "        movie_id = response.json()[\"results\"][0][\"id\"]\n",
    "        movie_response = requests.get(f\"https://api.themoviedb.org/3/movie/{movie_id}?api_key={tmdb_api_key}\")\n",
    "        movie_data = movie_response.json()\n",
    "        \n",
    "        # Extract the genre names into a list\n",
    "        genres = [genre[\"name\"] for genre in movie_data[\"genres\"]]\n",
    "\n",
    "\n",
    "        # Extract the spoken_languages' English name into a list\n",
    "        spoken_languages = [lang[\"english_name\"] for lang in movie_data[\"spoken_languages\"]]\n",
    "\n",
    "        # Extract the production_countries' name into a list\n",
    "        production_countries = [country[\"name\"] for country in movie_data[\"production_countries\"]]\n",
    "        # Add the relevant data to a dictionary and\n",
    "        # append it to the tmdb_movies_list list\n",
    "        movie_data_dict = {\n",
    "            \"title\": movie_data[\"title\"],\n",
    "            \"release_date\": movie_data[\"release_date\"],\n",
    "            \"runtime\": movie_data[\"runtime\"],\n",
    "            \"genres\": genres,\n",
    "            \"spoken_languages\": spoken_languages,\n",
    "            \"production_countries\": production_countries\n",
    "        }\n",
    "        tmdb_movies_list.append(movie_data_dict)\n",
    "        # Print out the title that was found\n",
    "        print(f\"Movie found: {title}\")\n",
    "\n",
    "    except IndexError:\n",
    "        # Print out the title that was not found\n",
    "        print(f\"Movie not found: {title}\")\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"title\": \"The Attachment Diaries\",\n",
      "        \"release_date\": \"2021-10-07\",\n",
      "        \"runtime\": 102,\n",
      "        \"genres\": [\n",
      "            \"Drama\",\n",
      "            \"Mystery\",\n",
      "            \"Thriller\",\n",
      "            \"Horror\"\n",
      "        ],\n",
      "        \"spoken_languages\": [\n",
      "            \"Spanish\"\n",
      "        ],\n",
      "        \"production_countries\": [\n",
      "            \"Argentina\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Bread\",\n",
      "        \"release_date\": \"2008-09-08\",\n",
      "        \"runtime\": 30,\n",
      "        \"genres\": [\n",
      "            \"Drama\",\n",
      "            \"Crime\"\n",
      "        ],\n",
      "        \"spoken_languages\": [\n",
      "            \"Dutch\",\n",
      "            \"Kurdish\"\n",
      "        ],\n",
      "        \"production_countries\": [\n",
      "            \"Belgium\",\n",
      "            \"Iraq\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"You Can Live Forever\",\n",
      "        \"release_date\": \"2023-03-24\",\n",
      "        \"runtime\": 96,\n",
      "        \"genres\": [\n",
      "            \"Drama\",\n",
      "            \"Romance\"\n",
      "        ],\n",
      "        \"spoken_languages\": [\n",
      "            \"English\",\n",
      "            \"French\"\n",
      "        ],\n",
      "        \"production_countries\": [\n",
      "            \"Canada\",\n",
      "            \"United States of America\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"A Tourist's Guide to Love\",\n",
      "        \"release_date\": \"2023-04-21\",\n",
      "        \"runtime\": 96,\n",
      "        \"genres\": [\n",
      "            \"Romance\",\n",
      "            \"Comedy\"\n",
      "        ],\n",
      "        \"spoken_languages\": [\n",
      "            \"English\",\n",
      "            \"Vietnamese\"\n",
      "        ],\n",
      "        \"production_countries\": [\n",
      "            \"United States of America\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Other People's Children\",\n",
      "        \"release_date\": \"2022-09-21\",\n",
      "        \"runtime\": 104,\n",
      "        \"genres\": [\n",
      "            \"Drama\",\n",
      "            \"Comedy\"\n",
      "        ],\n",
      "        \"spoken_languages\": [\n",
      "            \"English\",\n",
      "            \"French\"\n",
      "        ],\n",
      "        \"production_countries\": [\n",
      "            \"France\"\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Preview the first 5 results in JSON format\n",
    "# Use json.dumps with argument indent=4 to format data\n",
    "print(json.dumps(tmdb_movies_list[:5], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>production_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Attachment Diaries</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>102</td>\n",
       "      <td>[Drama, Mystery, Thriller, Horror]</td>\n",
       "      <td>[Spanish]</td>\n",
       "      <td>[Argentina]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread</td>\n",
       "      <td>2008-09-08</td>\n",
       "      <td>30</td>\n",
       "      <td>[Drama, Crime]</td>\n",
       "      <td>[Dutch, Kurdish]</td>\n",
       "      <td>[Belgium, Iraq]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You Can Live Forever</td>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>96</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>[English, French]</td>\n",
       "      <td>[Canada, United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Tourist's Guide to Love</td>\n",
       "      <td>2023-04-21</td>\n",
       "      <td>96</td>\n",
       "      <td>[Romance, Comedy]</td>\n",
       "      <td>[English, Vietnamese]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other People's Children</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>104</td>\n",
       "      <td>[Drama, Comedy]</td>\n",
       "      <td>[English, French]</td>\n",
       "      <td>[France]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>One True Loves</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>100</td>\n",
       "      <td>[Romance, Drama, Comedy]</td>\n",
       "      <td>[English, Spanish]</td>\n",
       "      <td>[Czech Republic, United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Lost Weekend: A Love Story</td>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>95</td>\n",
       "      <td>[Documentary]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Thousand and One</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>116</td>\n",
       "      <td>[Drama, Crime]</td>\n",
       "      <td>[English, Portuguese, Spanish]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Your Place or Mine</td>\n",
       "      <td>2023-02-10</td>\n",
       "      <td>109</td>\n",
       "      <td>[Romance, Comedy]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Love in the Time of Fentanyl</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>85</td>\n",
       "      <td>[Documentary]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[Canada, United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pamela, A Love Story</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>113</td>\n",
       "      <td>[Documentary]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>In from the Side</td>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>134</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>After Love</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>89</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[English, Arabic, French, Urdu]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alcarràs</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>120</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[Catalan]</td>\n",
       "      <td>[Spain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nelly and Monsieur Arnaud</td>\n",
       "      <td>1995-08-23</td>\n",
       "      <td>106</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>[French]</td>\n",
       "      <td>[Germany, France, Italy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lady Chatterley's Lover</td>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>126</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United Kingdom, United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Sound of Christmas</td>\n",
       "      <td>2022-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>[TV Movie, Drama]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Inspection</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>95</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[Arabic, Spanish, English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bones and All</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>131</td>\n",
       "      <td>[Drama, Horror, Romance]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[Italy, United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>My Policeman</td>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>113</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United Kingdom, United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>About Fate</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>100</td>\n",
       "      <td>[Romance, Comedy]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Waiting for Bojangles</td>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>124</td>\n",
       "      <td>[Drama, Comedy, Romance]</td>\n",
       "      <td>[English, French, Spanish]</td>\n",
       "      <td>[France, United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I Love My Dad</td>\n",
       "      <td>2022-08-05</td>\n",
       "      <td>90</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A Circus Tale &amp; A Love Song</td>\n",
       "      <td></td>\n",
       "      <td>114</td>\n",
       "      <td>[Romance, Drama]</td>\n",
       "      <td>[English, Spanish]</td>\n",
       "      <td>[Mexico]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Alone Together</td>\n",
       "      <td>2022-07-22</td>\n",
       "      <td>101</td>\n",
       "      <td>[Romance, Drama]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Art of Love</td>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>99</td>\n",
       "      <td>[Romance, Action, Drama]</td>\n",
       "      <td>[Turkish]</td>\n",
       "      <td>[Turkey]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2099: The Soldier Protocol</td>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>82</td>\n",
       "      <td>[Action, Science Fiction]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[Australia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thor: Love and Thunder</td>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>119</td>\n",
       "      <td>[Fantasy, Action, Comedy]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Both Sides of the Blade</td>\n",
       "      <td>2022-07-08</td>\n",
       "      <td>117</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>[French]</td>\n",
       "      <td>[France]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Fire of Love</td>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>93</td>\n",
       "      <td>[Documentary]</td>\n",
       "      <td>[English, French, Spanish, Portuguese]</td>\n",
       "      <td>[Canada, United States of America]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title release_date  runtime  \\\n",
       "0           The Attachment Diaries   2021-10-07      102   \n",
       "1                            Bread   2008-09-08       30   \n",
       "2             You Can Live Forever   2023-03-24       96   \n",
       "3        A Tourist's Guide to Love   2023-04-21       96   \n",
       "4          Other People's Children   2022-09-21      104   \n",
       "5                   One True Loves   2023-04-07      100   \n",
       "6   The Lost Weekend: A Love Story   2023-04-13       95   \n",
       "7               A Thousand and One   2023-03-31      116   \n",
       "8               Your Place or Mine   2023-02-10      109   \n",
       "9     Love in the Time of Fentanyl   2023-02-03       85   \n",
       "10            Pamela, A Love Story   2023-01-30      113   \n",
       "11                In from the Side   2022-09-16      134   \n",
       "12                      After Love   2021-06-04       89   \n",
       "13                        Alcarràs   2022-04-29      120   \n",
       "14       Nelly and Monsieur Arnaud   1995-08-23      106   \n",
       "15         Lady Chatterley's Lover   2022-11-22      126   \n",
       "16          The Sound of Christmas   2022-11-24        0   \n",
       "17                  The Inspection   2022-11-18       95   \n",
       "18                   Bones and All   2022-11-18      131   \n",
       "19                    My Policeman   2022-10-20      113   \n",
       "20                      About Fate   2022-09-08      100   \n",
       "21           Waiting for Bojangles   2021-10-13      124   \n",
       "22                   I Love My Dad   2022-08-05       90   \n",
       "23     A Circus Tale & A Love Song                   114   \n",
       "24                  Alone Together   2022-07-22      101   \n",
       "25                     Art of Love   2024-03-14       99   \n",
       "26      2099: The Soldier Protocol   2019-09-02       82   \n",
       "27          Thor: Love and Thunder   2022-07-06      119   \n",
       "28         Both Sides of the Blade   2022-07-08      117   \n",
       "29                    Fire of Love   2022-07-06       93   \n",
       "\n",
       "                                genres  \\\n",
       "0   [Drama, Mystery, Thriller, Horror]   \n",
       "1                       [Drama, Crime]   \n",
       "2                     [Drama, Romance]   \n",
       "3                    [Romance, Comedy]   \n",
       "4                      [Drama, Comedy]   \n",
       "5             [Romance, Drama, Comedy]   \n",
       "6                        [Documentary]   \n",
       "7                       [Drama, Crime]   \n",
       "8                    [Romance, Comedy]   \n",
       "9                        [Documentary]   \n",
       "10                       [Documentary]   \n",
       "11                    [Drama, Romance]   \n",
       "12                             [Drama]   \n",
       "13                             [Drama]   \n",
       "14                    [Drama, Romance]   \n",
       "15                    [Drama, Romance]   \n",
       "16                   [TV Movie, Drama]   \n",
       "17                             [Drama]   \n",
       "18            [Drama, Horror, Romance]   \n",
       "19                    [Drama, Romance]   \n",
       "20                   [Romance, Comedy]   \n",
       "21            [Drama, Comedy, Romance]   \n",
       "22                            [Comedy]   \n",
       "23                    [Romance, Drama]   \n",
       "24                    [Romance, Drama]   \n",
       "25            [Romance, Action, Drama]   \n",
       "26           [Action, Science Fiction]   \n",
       "27           [Fantasy, Action, Comedy]   \n",
       "28                    [Drama, Romance]   \n",
       "29                       [Documentary]   \n",
       "\n",
       "                          spoken_languages  \\\n",
       "0                                [Spanish]   \n",
       "1                         [Dutch, Kurdish]   \n",
       "2                        [English, French]   \n",
       "3                    [English, Vietnamese]   \n",
       "4                        [English, French]   \n",
       "5                       [English, Spanish]   \n",
       "6                                [English]   \n",
       "7           [English, Portuguese, Spanish]   \n",
       "8                                [English]   \n",
       "9                                [English]   \n",
       "10                               [English]   \n",
       "11                               [English]   \n",
       "12         [English, Arabic, French, Urdu]   \n",
       "13                               [Catalan]   \n",
       "14                                [French]   \n",
       "15                               [English]   \n",
       "16                               [English]   \n",
       "17              [Arabic, Spanish, English]   \n",
       "18                               [English]   \n",
       "19                               [English]   \n",
       "20                               [English]   \n",
       "21              [English, French, Spanish]   \n",
       "22                               [English]   \n",
       "23                      [English, Spanish]   \n",
       "24                               [English]   \n",
       "25                               [Turkish]   \n",
       "26                               [English]   \n",
       "27                               [English]   \n",
       "28                                [French]   \n",
       "29  [English, French, Spanish, Portuguese]   \n",
       "\n",
       "                          production_countries  \n",
       "0                                  [Argentina]  \n",
       "1                              [Belgium, Iraq]  \n",
       "2           [Canada, United States of America]  \n",
       "3                   [United States of America]  \n",
       "4                                     [France]  \n",
       "5   [Czech Republic, United States of America]  \n",
       "6                   [United States of America]  \n",
       "7                   [United States of America]  \n",
       "8                   [United States of America]  \n",
       "9           [Canada, United States of America]  \n",
       "10                  [United States of America]  \n",
       "11                            [United Kingdom]  \n",
       "12                            [United Kingdom]  \n",
       "13                                     [Spain]  \n",
       "14                    [Germany, France, Italy]  \n",
       "15  [United Kingdom, United States of America]  \n",
       "16                  [United States of America]  \n",
       "17                  [United States of America]  \n",
       "18           [Italy, United States of America]  \n",
       "19  [United Kingdom, United States of America]  \n",
       "20                  [United States of America]  \n",
       "21          [France, United States of America]  \n",
       "22                  [United States of America]  \n",
       "23                                    [Mexico]  \n",
       "24                  [United States of America]  \n",
       "25                                    [Turkey]  \n",
       "26                                 [Australia]  \n",
       "27                  [United States of America]  \n",
       "28                                    [France]  \n",
       "29          [Canada, United States of America]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results to a DataFrame\n",
    "tmdb_df = pd.DataFrame(tmdb_movies_list)\n",
    "tmdb_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and Clean the Data for Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge the New York Times reviews and TMDB DataFrames on title\n",
    "merged_df = pd.merge(df, tmdb_df, on=\"title\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'byline.person'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'byline.person'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Loop through the list of columns to fix\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns_to_fix:\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Convert the column to type 'str'\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     merged_df[column] \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Loop through characters to remove\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m character \u001b[38;5;129;01min\u001b[39;00m characters_to_remove:\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# Remove the character from the column\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'byline.person'"
     ]
    }
   ],
   "source": [
    "# Remove list brackets and quotation marks on the columns containing lists\n",
    "# Create a list of the columns that need fixing\n",
    "columns_to_fix = [\"genres\", \"spoken_languages\", \"production_countries\", \"keywords\", \"byline.person\", \"source\"]\n",
    "\n",
    "# Create a list of characters to remove\n",
    "characters_to_remove = [\"[\", \"]\", \"'\"]\n",
    "\n",
    "# Loop through the list of columns to fix\n",
    "for column in columns_to_fix:\n",
    "\n",
    "    # Convert the column to type 'str'\n",
    "    merged_df[column] = merged_df[column].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Loop through characters to remove\n",
    "    for character in characters_to_remove:\n",
    "\n",
    "        # Remove the character from the column\n",
    "        merged_df[column] = merged_df[column].str.replace(character, \"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the fixed DataFrame\n",
    "merged_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['web_url', 'snippet', 'source', 'keywords', 'pub_date', 'word_count',\n",
      "       'headline.main', 'headline.kicker', 'headline.content_kicker',\n",
      "       'headline.print_headline', 'headline.name', 'headline.seo',\n",
      "       'headline.sub', 'byline.original', 'byline.organization', 'title',\n",
      "       'release_date', 'runtime', 'genres', 'spoken_languages',\n",
      "       'production_countries'],\n",
      "      dtype='object')\n",
      "Column 'byline.person' does not exist in DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Print all column names\n",
    "print(merged_df.columns)\n",
    "\n",
    "# Check if \"byline.person\" is in columns before dropping\n",
    "if \"byline.person\" in merged_df.columns:\n",
    "    merged_df = merged_df.drop(columns=[\"byline.person\"])\n",
    "else:\n",
    "    print(\"Column 'byline.person' does not exist in DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['byline.person'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Drop \"byline.person\" column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbyline.person\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/core/frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexes/base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['byline.person'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop \"byline.person\" column\n",
    "merged_df = merged_df.drop(columns=[\"byline.person\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicate rows and reset index\n",
    "merged_df = merged_df.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV without the index\n",
    "merged_df.to_csv(\"output/nyt_movie_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
